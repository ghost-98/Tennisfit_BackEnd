{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c708020-642c-43f7-9a7c-2baf52805041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 사용 가능\n"
     ]
    }
   ],
   "source": [
    "# 지도 학습으로 유사도 검출\n",
    "import torch\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = 'cuda:0'\n",
    "    print('GPU 사용 가능')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('GPU 사용 불가')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0d84098-6122-4101-a039-025ba6596694",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_path = './video/v1.mp4'\n",
    "#test_dataset = extract_user_dataset(video_path)\n",
    "import numpy as np\n",
    "test_dataset = np.load('./video/v1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae14064-3bfd-41a7-a0a5-deef34be9280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader # Pytorch에서 데이터를 불러오고, 전처리하는 클래스\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, seq_data):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        for dic in seq_data:\n",
    "            self.X.append(dic['value'])\n",
    "            self.y.append(dic['key'])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.X[index]\n",
    "        label = self.y[index]\n",
    "        return torch.Tensor(np.array(data)), torch.tensor(np.array(int(label)))\n",
    "\n",
    "    def __len__(self):\n",
    "            return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc34fa7e-e08d-4907-8e85-646edaaf11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader # Pytorch에서 데이터를 불러오고, 전처리하는 클래스\n",
    "\n",
    "class AnomalyDetectionDataset(Dataset):\n",
    "    def __init__(self, seq_data):\n",
    "        self.dataset = []\n",
    "        for data in seq_data:\n",
    "            self.dataset.append(data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.dataset[index]\n",
    "        return torch.Tensor(np.array(data))\n",
    "        \n",
    "    def __len__(self):\n",
    "            return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d44b404-82c2-4572-b466-3c4e185d2097",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=100, hidden_size = 172, num_layers=1, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=172, hidden_size = 256, num_layers=1, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(input_size=256, hidden_size = 512, num_layers=1, batch_first=True)\n",
    "        self.lstm4 = nn.LSTM(input_size=512, hidden_size = 256, num_layers=1, batch_first=True)\n",
    "        self.lstm5 = nn.LSTM(input_size=256, hidden_size = 128, num_layers=1, batch_first=True)\n",
    "        self.lstm6 = nn.LSTM(input_size=128, hidden_size = 64, num_layers=1, batch_first=True)\n",
    "        self.lstm7 = nn.LSTM(input_size=64, hidden_size = 32, num_layers=1, batch_first=True)\n",
    "        self.lstm8 = nn.LSTM(input_size=32, hidden_size = 16, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(16, 7)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm4(x)\n",
    "        x, _ = self.lstm5(x)\n",
    "        x, _ = self.lstm6(x)\n",
    "        x = self.dropout2(x)\n",
    "        x, _ = self.lstm7(x)\n",
    "        x, _ = self.lstm8(x)\n",
    "        x = self.fc(x[:,-1,:])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05f53d08-c82a-433e-a039-3ae4114c6dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swing016Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Swing016Model, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=100, hidden_size = 2048, num_layers=1, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=2048, hidden_size = 512, num_layers=1, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(input_size=512, hidden_size = 256, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(256, 10)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        x = self.fc(x[:,-1,:])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a91d7066-bdda-433c-9ed1-280e32703862",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swing2Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Swing2Model, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=100, hidden_size = 256, num_layers=1, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=256, hidden_size = 64, num_layers=1, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(input_size=64, hidden_size = 16, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(16, 10)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        x = self.fc(x[:,-1,:])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "073b95c8-b136-47ff-8e1f-40542543107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swing34Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Swing34Model, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=100, hidden_size = 64, num_layers=1, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=64, hidden_size = 32, num_layers=1, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(input_size=32, hidden_size = 16, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(16, 10)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        x = self.fc(x[:,-1,:])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d697dafd-047b-4a88-aa2b-0aa0ffb2d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swing5Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Swing5Model, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=100, hidden_size = 256, num_layers=1, batch_first=True)\n",
    "        self.lstm6 = nn.LSTM(input_size=256, hidden_size = 128, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(128, 10)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm6(x)\n",
    "        x = self.fc(x[:,-1,:])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "920148c6-0b9c-40a3-96c8-9ca3e3cc48af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size=100, hidden_size=50, num_layers=2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,\n",
    "                            dropout=0.3, bidirectional=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs, (hidden, cell) = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        return (hidden, cell)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size=100, hidden_size=50, output_size=100, num_layers=2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,\n",
    "                            dropout=0.3, bidirectional=False)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        output, (hidden, cell) = self.lstm(x, hidden)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        prediction = self.fc(output)\n",
    "\n",
    "        return prediction, (hidden, cell)\n",
    "    \n",
    "## LSTM Auto Encoder\n",
    "class LSTMAutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 latent_dim: int,\n",
    "                 sequence_length: int=1,\n",
    "                 **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        :param input_dim: 변수 Tag 갯수\n",
    "        :param latent_dim: 최종 압축할 차원 크기\n",
    "        :param sequence length: sequence 길이\n",
    "        :param kwargs:\n",
    "        \"\"\"\n",
    "\n",
    "        super(LSTMAutoEncoder, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        if \"num_layers\" in kwargs:\n",
    "            num_layers = kwargs.pop(\"num_layers\")\n",
    "        else:\n",
    "            num_layers = 1\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=latent_dim,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.reconstruct_decoder = Decoder(\n",
    "            input_size=input_dim,\n",
    "            output_size=input_dim,\n",
    "            hidden_size=latent_dim,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "\n",
    "    def forward(self, src:torch.Tensor, **kwargs):\n",
    "        batch_size, sequence_length, var_length = src.size()\n",
    "\n",
    "        ## Encoder 넣기t\n",
    "        encoder_hidden = self.encoder(src)\n",
    "        \n",
    "        inv_idx = torch.arange(sequence_length - 1, -1, -1).long()\n",
    "        reconstruct_output = []\n",
    "        temp_input = torch.zeros((batch_size, 1, var_length), dtype=torch.float).to(src.device)\n",
    "        hidden = encoder_hidden\n",
    "        for t in range(sequence_length):\n",
    "            temp_input, hidden = self.reconstruct_decoder(temp_input, hidden)\n",
    "            reconstruct_output.append(temp_input)\n",
    "        reconstruct_output = torch.cat(reconstruct_output, dim=1)[:, inv_idx, :]\n",
    "        \n",
    "        return [reconstruct_output, src]\n",
    "\n",
    "    def loss_function(self,\n",
    "                      *args,\n",
    "                      **kwargs) -> dict:\n",
    "        recons = args[0]\n",
    "        input = args[1]\n",
    "        \n",
    "        ## MSE loss(Mean squared Error)\n",
    "        loss =F.mse_loss(recons, input)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11bb605c-d8e1-4e22-bcf9-4aa4046a645d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 세팅\n",
    "import joblib\n",
    "\n",
    "classification_model = ClassificationModel().to(device)\n",
    "forehand_model = Swing016Model().to(device)\n",
    "backhand_model = Swing016Model().to(device)\n",
    "serve_model = Swing016Model().to(device)\n",
    "backslice_model = Swing2Model().to(device)\n",
    "forevolley_model = Swing34Model().to(device)\n",
    "backvolley_model = Swing34Model().to(device)\n",
    "smash_model = Swing5Model().to(device)\n",
    "anomaly_detection_model = LSTMAutoEncoder(input_dim=100, latent_dim=50, sequence_length=60, num_layers=6).to(device)\n",
    "\n",
    "# 모델 불러오기\n",
    "classification_model.load_state_dict(torch.load('./model/model_info/classification_model', map_location=device))\n",
    "forehand_model.load_state_dict(torch.load('./model/model_info/similarity_model_forehand', map_location=device))\n",
    "backhand_model.load_state_dict(torch.load('./model/model_info/similarity_model_backhand', map_location=device))\n",
    "serve_model.load_state_dict(torch.load('./model/model_info/similarity_model_serve', map_location=device))\n",
    "backslice_model.load_state_dict(torch.load('./model/model_info/similarity_model_backslice', map_location=device))\n",
    "forevolley_model.load_state_dict(torch.load('./model/model_info/similarity_model_forevolley', map_location=device))\n",
    "backvolley_model.load_state_dict(torch.load('./model/model_info/similarity_model_backvolley', map_location=device))\n",
    "smash_model.load_state_dict(torch.load('./model/model_info/similarity_model_smash', map_location=device))\n",
    "anomaly_detection_model.load_state_dict(torch.load('./model/model_info/anomaly_detection_model', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47309fb6-6949-4a71-9de9-38ec09040993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "classification_model.eval()\n",
    "forehand_model.eval()\n",
    "backhand_model.eval()\n",
    "serve_model.eval()\n",
    "smash_model.eval()\n",
    "backslice_model.eval()\n",
    "forevolley_model.eval()\n",
    "backvolley_model.eval()\n",
    "anomaly_detection_model.eval()\n",
    "\n",
    "test_data = []\n",
    "anomaly_detection_data = []\n",
    "\n",
    "for data in test_dataset:\n",
    "    test_data.append({'key': 8, 'value': data})\n",
    "    anomaly_detection_data.append(data)\n",
    "\n",
    "test_data = TestDataset(test_data)\n",
    "test_data = DataLoader(test_data)\n",
    "anomaly_detection_data = AnomalyDetectionDataset(anomaly_detection_data)\n",
    "anomaly_detection_data = DataLoader(anomaly_detection_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ff95be5-c73c-42c8-87c5-44a649b54176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1020/1020 [00:45<00:00, 22.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# Classification, Similarity 계산\n",
    "test_data_list = []\n",
    "\n",
    "for data, label in tqdm(test_data):\n",
    "    data = data.to(device)\n",
    "    data_list = []\n",
    "    with torch.no_grad():\n",
    "        classification_result = classification_model(data)\n",
    "        classification_result = F.softmax(classification_result, dim=1)\n",
    "        out_result, out = torch.max(classification_result, 1)\n",
    "\n",
    "        if out.item() == 0: \n",
    "            swing_result = forehand_model(data)\n",
    "            data_list.append('Forehand')\n",
    "        elif out.item() == 1: \n",
    "            swing_result = backhand_model(data)\n",
    "            data_list.append('Backhand')\n",
    "        elif out.item() == 2: \n",
    "            swing_result = backslice_model(data)\n",
    "            data_list.append('Backslice')\n",
    "        elif out.item() == 3: \n",
    "            swing_result = forevolley_model(data)\n",
    "            data_list.append('ForeVolley')\n",
    "        elif out.item() == 4: \n",
    "            swing_result = backvolley_model(data)\n",
    "            data_list.append('BackVolley')\n",
    "        elif out.item() == 5: \n",
    "            swing_result = smash_model(data)\n",
    "            data_list.append('Smash')\n",
    "        elif out.item() == 6: \n",
    "            swing_result = serve_model(data)\n",
    "            data_list.append('Serve')\n",
    "\n",
    "        swing_result = F.softmax(swing_result, dim=1).squeeze()\n",
    "        data_list.append(swing_result)\n",
    "        \n",
    "        test_data_list.append(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d91d7fa-21fd-43a6-b203-33f811d1aa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|                                                                                                                             | 0/1020 [00:00<?, ?it/s]C:\\Users\\yhjmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Testing: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1020/1020 [00:13<00:00, 74.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# data anomaly detection loss 계산하기\n",
    "anomaly_detection_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _data in tqdm(anomaly_detection_data, desc='Testing'):\n",
    "        data = _data.to(device)\n",
    "        predict_values = anomaly_detection_model(data)\n",
    "\n",
    "        ## MAE(Mean Absolute Error)로 계산\n",
    "        loss = F.l1_loss(predict_values[0], predict_values[1], reduce=False)\n",
    "        #loss = loss.sum(dim=2).sum(dim=1).cpu().numpy()\n",
    "        loss = loss.mean(dim=1).cpu().numpy()\n",
    "        anomaly_detection_list.append(loss)\n",
    "anomaly_detection_list = np.concatenate(anomaly_detection_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8909275-2bfc-496f-a057-64a27d2aabb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1020/1020 [00:00<00:00, 15224.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# 비정상 점수 계산\n",
    "\n",
    "# Reconstruction Error의 평균과 Covarinace 계산\n",
    "mean = np.mean(anomaly_detection_list, axis=0)\n",
    "std = np.cov(anomaly_detection_list.T)\n",
    "\n",
    "class Anomaly_Calculator:\n",
    "    def __init__(self, mean:np.array, std:np.array):\n",
    "        assert mean.shape[0] == std.shape[0] and mean.shape[0] == std.shape[1], '평균과 분산의 차원이 똑같아야 합니다.'\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def __call__(self, recons_error:np.array):\n",
    "        x = (recons_error-self.mean)\n",
    "        return np.matmul(np.matmul(x, self.std), x.T)\n",
    "\n",
    "anomaly_calculator = Anomaly_Calculator(mean, std)\n",
    "\n",
    "anomaly_scores = []\n",
    "for temp_loss in tqdm(anomaly_detection_list):\n",
    "    temp_score = anomaly_calculator(temp_loss)\n",
    "    anomaly_scores.append(temp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c17b9a6a-b916-47d4-8d7b-98b659114e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABDiUlEQVR4nO3de1yUdf7//+dwGkQFSxI8oFi6KXk+wGJt9ikSW3eLzVUzSyI/9m2T0uhjiZWH7YCZulRaru1Hq0+R1m66thrFkqeSPFvr2Y6YBmgmqCQSXL8/+jE5MiDgDNcM1+N+u3Fz5j3vua7X+31dMzy9rmsGm2EYhgAAACzEz+wCAAAAGhsBCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCAAAWA4BCECj+frrr2Wz2fTKK6+YXUq9XHfddbruuuvMLgOAGxGAALjFK6+8IpvNpq1bt7p92S+++GKdQtM777wjm82mv/3tbzX2ycnJkc1m0/PPP+/GCgH4GgIQgEbTqVMn/fjjj7rzzjvr9by6BqBhw4YpLCxMWVlZNfbJysqSv7+/brvttnrVAKBpIQABaDQ2m03BwcHy9/f3yPLtdrv++Mc/at26dTpy5Ei1x8+cOaPly5frxhtvVJs2bTxSAwDfQAAC0GhcXQNUUFCglJQUdejQQXa7XW3bttUtt9yir7/+WpIUHR2t3bt3a926dbLZbLLZbLVej3PHHXeosrJSS5curfbYqlWrVFxcrDFjxkiSlixZouuvv15t2rSR3W5XTEyMXnrppQuOo+p0X1WNVdauXSubzaa1a9c6tW/atElDhw5VWFiYQkJCNHjwYH388cdOfU6ePKlJkyYpOjpadrtdbdq00Y033qjt27dfsB4A9RdgdgEArG348OHavXu37r//fkVHR6uoqEg5OTnKz89XdHS0MjMzdf/996tFixZ69NFHJUkRERE1Lu/aa69Vhw4dlJWVpbS0NKfHsrKyFBISoqSkJEnSSy+9pKuuuko333yzAgIC9O677+q+++5TZWWlJkyY4Jbxffjhh7rpppvUv39/TZ8+XX5+fo7gtWHDBsXGxkqS7r33Xv39739XamqqYmJi9P333+ujjz7S3r171a9fP7fUAuAcBgC4wZIlSwxJxpYtW2rs89VXXxmSjCVLlhiGYRg//PCDIcl49tlna132VVddZQwePLjOtUyePNmQZOzfv9/RVlxcbAQHBxujR492tJWWllZ7bmJionH55Zc7tQ0ePNhp/VVj/eqrr5z6rVmzxpBkrFmzxjAMw6isrDS6du1qJCYmGpWVlU7r7dy5s3HjjTc62sLCwowJEybUeYwALg6nwACYplmzZgoKCtLatWv1ww8/uG25d9xxhyQ5XQz9j3/8Q2fOnHGc/qpaf5Xi4mIdO3ZMgwcP1pdffqni4uKLrmPnzp06ePCgbr/9dn3//fc6duyYjh07ptOnT+uGG27Q+vXrVVlZKUlq1aqVNm3a5PLaJQDuRwACYBq73a5nnnlG7733niIiInTttddq9uzZKigouKjl9urVSz169NCbb77paMvKylJ4eLgSExMdbR9//LESEhLUvHlztWrVSpdddpmmTp0qSW4JQAcPHpQkJScn67LLLnP6+dvf/qaysjLHembPnq1du3YpKipKsbGxmjFjhr788suLrgGAawQgAKaaNGmSDhw4oIyMDAUHB+vxxx9X9+7dtWPHjota7h133KEDBw5o69atKigo0Jo1azRy5EgFBPx86eMXX3yhG264QceOHdO8efO0atUq5eTk6MEHH5Qkx5EZV2w2m8v2iooKp/tVy3j22WeVk5Pj8qdFixaSpJEjR+rLL7/UCy+8oHbt2unZZ5/VVVddpffee++i5gGAa1wEDcB0V1xxhR566CE99NBDOnjwoPr06aO5c+fq9ddfl1Rz4KjN6NGjlZ6erqysLHXq1EkVFRVOp7/effddlZWVaeXKlerYsaOjfc2aNRdc9iWXXCJJOnHihFP7N998U21ckhQaGqqEhIQLLrdt27a67777dN9996moqEj9+vXTU089pZtuuumCzwVQPxwBAmCa0tJSnTlzxqntiiuuUMuWLVVWVuZoa968ebWwcSEdO3bUb37zGy1btkyvv/66OnfurEGDBjker/ouIsMwHG3FxcVasmTJBZddFWzWr1/vaKuoqNCiRYuc+vXv319XXHGF5syZo1OnTlVbztGjRx3PPf+UW5s2bdSuXTuneQDgPhwBAuBWixcvVnZ2drX2iRMnVms7cOCAbrjhBo0cOVIxMTEKCAjQ8uXLVVhY6PRNzf3799dLL72kJ598Ul26dFGbNm10/fXXX7CWO+64Q/fcc4+OHDni+Ah9lSFDhigoKEi///3v9f/+3//TqVOn9PLLL6tNmzb67rvval3uVVddpV//+tdKT0/X8ePHdemll2rp0qX66aefnPr5+fnpb3/7m2666SZdddVVSklJUfv27XX48GGtWbNGoaGhevfdd3Xy5El16NBBf/zjH9W7d2+1aNFC//73v7VlyxbNnTv3guME0ABmfwwNQNNQ9dHwmn4OHTpU7WPwx44dMyZMmGB069bNaN68uREWFmbExcUZb731ltOyCwoKjGHDhhktW7Y0JNX5I/HHjx837Ha7IcnYs2dPtcdXrlxp9OrVywgODjaio6ONZ555xli8eHG1j7if/zF4wzCML774wkhISDDsdrsRERFhTJ061cjJyXH6GHyVHTt2GLfeeqvRunVrw263G506dTJGjhxp5ObmGoZhGGVlZcbkyZON3r17Gy1btjSaN29u9O7d23jxxRfrNE4A9WczjHOO/wIAAFgA1wABAADLIQABAADLIQABAADLIQABAADLIQABAADLIQABAADL4YsQXaisrNSRI0fUsmXLBn0FPwAAaHyGYejkyZNq166d/PxqP8ZDAHLhyJEjioqKMrsMAADQAIcOHVKHDh1q7UMAcqFly5aSfp7A0NBQk6sBAAB1UVJSoqioKMfv8doQgFyoOu0VGhpKAAIAwMfU5fIVLoIGAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACAACWQwACALhN9JRVZpcA1AkBCAAAWA4BCAAAWA4BCAAAWI7pAWjBggWKjo5WcHCw4uLitHnz5hr77t69W8OHD1d0dLRsNpsyMzNd9jt8+LDuuOMOtW7dWs2aNVPPnj21detWD40AAAD4GlMD0LJly5SWlqbp06dr+/bt6t27txITE1VUVOSyf2lpqS6//HLNmjVLkZGRLvv88MMPuvrqqxUYGKj33ntPe/bs0dy5c3XJJZd4cigAAMCHBJi58nnz5mn8+PFKSUmRJC1cuFCrVq3S4sWLNWXKlGr9Bw4cqIEDB0qSy8cl6ZlnnlFUVJSWLFniaOvcubMHqgcAAL7KtAB09uxZbdu2Tenp6Y42Pz8/JSQkKC8vr8HLXblypRITEzVixAitW7dO7du313333afx48fX+JyysjKVlZU57peUlEiSysvLVV5e3uBaAMBq7P4G75swTX32PdMC0LFjx1RRUaGIiAin9oiICO3bt6/By/3yyy/10ksvKS0tTVOnTtWWLVv0wAMPKCgoSMnJyS6fk5GRoZkzZ1Zr/+CDDxQSEtLgWgDAambHSqtXrza7DFhUaWlpnfuaegrMEyorKzVgwAA9/fTTkqS+fftq165dWrhwYY0BKD09XWlpaY77JSUlioqK0pAhQxQaGtoodQNAU9BjxvvaNSPR7DJgUVVncOrCtAAUHh4uf39/FRYWOrUXFhbWeIFzXbRt21YxMTFObd27d9c//vGPGp9jt9tlt9urtQcGBiowMLDBtQCA1ZRV2HjfhGnqs++Z9imwoKAg9e/fX7m5uY62yspK5ebmKj4+vsHLvfrqq7V//36ntgMHDqhTp04NXiYAAGhaTD0FlpaWpuTkZA0YMECxsbHKzMzU6dOnHZ8KGzt2rNq3b6+MjAxJP184vWfPHsftw4cPa+fOnWrRooW6dOkiSXrwwQc1aNAgPf300xo5cqQ2b96sRYsWadGiReYMEgAAeB1TA9CoUaN09OhRTZs2TQUFBerTp4+ys7MdF0bn5+fLz++Xg1RHjhxR3759HffnzJmjOXPmaPDgwVq7dq2knz8qv3z5cqWnp+vPf/6zOnfurMzMTI0ZM6ZRxwYAALyXzTAMw+wivE1JSYnCwsJUXFzMRdAAUA/RU1bp61nDzC4DFlWf39+m/ykMAACAxkYAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgAAlkMAAgC4RfSUVWaXANQZAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFgOAQgAAFiOVwSgBQsWKDo6WsHBwYqLi9PmzZtr7Lt7924NHz5c0dHRstlsyszMrHXZs2bNks1m06RJk9xbNAAA8FmmB6Bly5YpLS1N06dP1/bt29W7d28lJiaqqKjIZf/S0lJdfvnlmjVrliIjI2td9pYtW/TXv/5VvXr18kTpAADAR5kegObNm6fx48crJSVFMTExWrhwoUJCQrR48WKX/QcOHKhnn31Wt912m+x2e43LPXXqlMaMGaOXX35Zl1xyiafKBwAAPijAzJWfPXtW27ZtU3p6uqPNz89PCQkJysvLu6hlT5gwQcOGDVNCQoKefPLJWvuWlZWprKzMcb+kpESSVF5ervLy8ouqAwCswu5vSBLvmzBNffY9UwPQsWPHVFFRoYiICKf2iIgI7du3r8HLXbp0qbZv364tW7bUqX9GRoZmzpxZrf2DDz5QSEhIg+sAACuZHfvzv6tXrza3EFhWaWlpnfuaGoA84dChQ5o4caJycnIUHBxcp+ekp6crLS3Ncb+kpERRUVEaMmSIQkNDPVUqADQpPWa8L0naNSPR5EpgVVVncOrC1AAUHh4uf39/FRYWOrUXFhZe8ALnmmzbtk1FRUXq16+fo62iokLr16/X/PnzVVZWJn9/f6fn2O12l9cTBQYGKjAwsEF1AIDVlFXYJIn3TZimPvueqRdBBwUFqX///srNzXW0VVZWKjc3V/Hx8Q1a5g033KD//Oc/2rlzp+NnwIABGjNmjHbu3Fkt/AAAAOsx/RRYWlqakpOTNWDAAMXGxiozM1OnT59WSkqKJGns2LFq3769MjIyJP184fSePXsctw8fPqydO3eqRYsW6tKli1q2bKkePXo4raN58+Zq3bp1tXYAAGBNpgegUaNG6ejRo5o2bZoKCgrUp08fZWdnOy6Mzs/Pl5/fLweqjhw5or59+zruz5kzR3PmzNHgwYO1du3axi4fAAD4IJthGIbZRXibkpIShYWFqbi4mIugAaCOoqeskiR9PWuYyZXAqurz+9v0L0IEAABobAQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAABgOQQgAIBbVf1RVMCbEYAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDlEIAAAIDleEUAWrBggaKjoxUcHKy4uDht3ry5xr67d+/W8OHDFR0dLZvNpszMzGp9MjIyNHDgQLVs2VJt2rRRUlKS9u/f78ERAAAAX2J6AFq2bJnS0tI0ffp0bd++Xb1791ZiYqKKiopc9i8tLdXll1+uWbNmKTIy0mWfdevWacKECfrkk0+Uk5Oj8vJyDRkyRKdPn/bkUAAAgI+wGYZhmFlAXFycBg4cqPnz50uSKisrFRUVpfvvv19Tpkyp9bnR0dGaNGmSJk2aVGu/o0ePqk2bNlq3bp2uvfbaC9ZUUlKisLAwFRcXKzQ0tM5jAQAri56yynH761nDTKwEVlWf398BjVSTS2fPntW2bduUnp7uaPPz81NCQoLy8vLctp7i4mJJ0qWXXury8bKyMpWVlTnul5SUSJLKy8tVXl7utjoAoCmz+//y/2neO2GG+ux3pgagY8eOqaKiQhEREU7tERER2rdvn1vWUVlZqUmTJunqq69Wjx49XPbJyMjQzJkzq7V/8MEHCgkJcUsdANDUzY795fbq1avNKwSWVVpaWue+pgagxjBhwgTt2rVLH330UY190tPTlZaW5rhfUlKiqKgoDRkyhFNgAFBHPWa877i9a0aiiZXAqqrO4NSFqQEoPDxc/v7+KiwsdGovLCys8QLn+khNTdW//vUvrV+/Xh06dKixn91ul91ur9YeGBiowMDAi64DAKygrMLmuM17J8xQn/3O1E+BBQUFqX///srNzXW0VVZWKjc3V/Hx8Q1ermEYSk1N1fLly/Xhhx+qc+fO7igXAAA0EaafAktLS1NycrIGDBig2NhYZWZm6vTp00pJSZEkjR07Vu3bt1dGRoakny+c3rNnj+P24cOHtXPnTrVo0UJdunSR9PNpr6ysLP3zn/9Uy5YtVVBQIEkKCwtTs2bNTBglAADwJqYHoFGjRuno0aOaNm2aCgoK1KdPH2VnZzsujM7Pz5ef3y8Hqo4cOaK+ffs67s+ZM0dz5szR4MGDtXbtWknSSy+9JEm67rrrnNa1ZMkS3XXXXR4dDwAA8H6mfw+QN+J7gACg/vgeIJitPr+/Tf8maAAAgMZGAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIa4NzvOwEA+B4CEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsBwCEAAAsByvCEALFixQdHS0goODFRcXp82bN9fYd/fu3Ro+fLiio6Nls9mUmZl50csEAADWYnoAWrZsmdLS0jR9+nRt375dvXv3VmJiooqKilz2Ly0t1eWXX65Zs2YpMjLSLcsEAADWYnoAmjdvnsaPH6+UlBTFxMRo4cKFCgkJ0eLFi132HzhwoJ599lnddtttstvtblkmAACwlgAzV3727Flt27ZN6enpjjY/Pz8lJCQoLy+v0ZZZVlamsrIyx/2SkhJJUnl5ucrLyxtUB5o2u7/BvgGcx+5vOG7z+oAZ6rPfmRqAjh07poqKCkVERDi1R0REaN++fY22zIyMDM2cObNa+wcffKCQkJAG1YGmbXastHr1arPLALzK7NhfbvP6gBlKS0vr3NfUAOQt0tPTlZaW5rhfUlKiqKgoDRkyRKGhoSZWBm/VY8b72jUj0ewyAK/SY8b7jtu8PmCGqjM4dWFqAAoPD5e/v78KCwud2gsLC2u8wNkTy7Tb7S6vJwoMDFRgYGCD6kDTVlZhY98AzlNWYXPc5vUBM9RnvzP1IuigoCD1799fubm5jrbKykrl5uYqPj7ea5YJAACaFtNPgaWlpSk5OVkDBgxQbGysMjMzdfr0aaWkpEiSxo4dq/bt2ysjI0PSzxc579mzx3H78OHD2rlzp1q0aKEuXbrUaZkAAMDaTA9Ao0aN0tGjRzVt2jQVFBSoT58+ys7OdlzEnJ+fLz+/Xw5UHTlyRH379nXcnzNnjubMmaPBgwdr7dq1dVomAACwNpthGMaFu1lLSUmJwsLCVFxczEXQcCl6yip9PWuY2WUAXiV6yirHbV4fMEN9fn+b/kWIAAAAjY0ABAAALIcABAAALIcABAAALIcABAAALIcABAAALKdBAeinn37Sv//9b/31r3/VyZMnJf38/TynTp1ya3EAAACeUO8vQvzmm280dOhQ5efnq6ysTDfeeKNatmypZ555RmVlZVq4cKEn6gQAAHCbeh8BmjhxogYMGKAffvhBzZo1c7T/4Q9/cPr7WwAAAN6q3keANmzYoI0bNyooKMipPTo6WocPH3ZbYQAAAJ5S7yNAlZWVqqioqNb+7bffqmXLlm4pCgAAwJPqHYCGDBmizMxMx32bzaZTp05p+vTp+u1vf+vO2gAAADyi3qfA5s6dq8TERMXExOjMmTO6/fbbdfDgQYWHh+vNN9/0RI0AAABuVe8A1KFDB3366adaunSpPvvsM506dUrjxo3TmDFjnC6KBgAA8Fb1DkCSFBAQoDvuuMPdtQAAADSKegeg1157rdbHx44d2+BiAAAAGkO9A9DEiROd7peXl6u0tFRBQUEKCQkhAAEALCt6yip9PWuY2WWgDur9KbAffvjB6efUqVPav3+/rrnmGi6CBgAAPsEtfwy1a9eumjVrVrWjQwAAAN7IbX8NPiAgQEeOHHHX4gAAADym3tcArVy50um+YRj67rvvNH/+fF199dVuKwwAfBnXggDerd4BKCkpyem+zWbTZZddpuuvv15z5851V10AAAAeU+8AVFlZ6Yk6AAAAGo3brgECAADwFXU6ApSWllbnBc6bN6/BxQAAADSGOgWgHTt21GlhNpvtoooBAABoDHUKQGvWrPF0HQAAAI2Ga4AAAIDlNOivwW/dulVvvfWW8vPzdfbsWafH3nnnHbcUBgAA4Cn1PgK0dOlSDRo0SHv37tXy5ctVXl6u3bt368MPP1RYWJgnagQAAHCregegp59+Wn/5y1/07rvvKigoSM8995z27dunkSNHqmPHjp6oEQAAwK3qHYC++OILDRv289e7BwUF6fTp07LZbHrwwQe1aNEitxcIAADgbvUOQJdccolOnjwpSWrfvr127dolSTpx4oRKS0sbVMSCBQsUHR2t4OBgxcXFafPmzbX2f/vtt9WtWzcFBwerZ8+eWr16tdPjp06dUmpqqjp06KBmzZopJiZGCxcubFBtAACg6alzAKoKOtdee61ycnIkSSNGjNDEiRM1fvx4jR49WjfccEO9C1i2bJnS0tI0ffp0bd++Xb1791ZiYqKKiopc9t+4caNGjx6tcePGaceOHUpKSlJSUpKjPunnL27Mzs7W66+/rr1792rSpElKTU2t9odcAQCANdU5APXq1UtxcXHq2bOnRowYIUl69NFHlZaWpsLCQg0fPlz/+7//W+8C5s2bp/HjxyslJcVxpCYkJESLFy922f+5557T0KFDNXnyZHXv3l1PPPGE+vXrp/nz5zv6bNy4UcnJybruuusUHR2te+65R717977gkSUAAGANdf4Y/Lp167RkyRJlZGToqaee0vDhw/Xf//3fmjJlSoNXfvbsWW3btk3p6emONj8/PyUkJCgvL8/lc/Ly8qr9aY7ExEStWLHCcX/QoEFauXKl7r77brVr105r167VgQMH9Je//MXlMsvKylRWVua4X1JSIkkqLy9XeXl5Q4eHJszub7BvoFZW3Efs/objttXGXsWK292b1Gfu6xyAfvOb3+g3v/mNXnjhBb311lt65ZVXNHjwYHXp0kXjxo1TcnKyIiMj61XosWPHVFFRoYiICKf2iIgI7du3z+VzCgoKXPYvKChw3H/hhRd0zz33qEOHDgoICJCfn59efvllXXvttS6XmZGRoZkzZ1Zr/+CDDxQSElKvMcEaZseq2rVnwLmsuI/Mjv3lttXGXsWK292b1Oda5Hp/EWLz5s2VkpKilJQUff7551qyZIkWLFigxx9/XEOHDvWK62xeeOEFffLJJ1q5cqU6deqk9evXa8KECWrXrp0SEhKq9U9PT3c6qlRSUqKoqCgNGTJEoaGhjVk6fESPGe9r14xEs8uAF7PiPtJjxvuO21YbexUrbndvUnUGpy4a9E3QVbp06aKpU6eqU6dOSk9P16pVq+r1/PDwcPn7+6uwsNCpvbCwsMajSZGRkbX2//HHHzV16lQtX77c8XH9Xr16aefOnZozZ47LAGS322W326u1BwYGKjAwsF5jgjWUVdjYN1ArK+4jZRW//EFsq429ihW3uzepz9w3+G+BrV+/XnfddZciIyM1efJk3Xrrrfr444/rtYygoCD1799fubm5jrbKykrl5uYqPj7e5XPi4+Od+ktSTk6Oo3/VdTt+fs5D8/f3V2VlZb3qAwAATVO9jgAdOXJEr7zyil555RV9/vnnGjRokJ5//nmNHDlSzZs3b1ABaWlpSk5O1oABAxQbG6vMzEydPn1aKSkpkqSxY8eqffv2ysjIkCRNnDhRgwcP1ty5czVs2DAtXbpUW7dudXwJY2hoqAYPHqzJkyerWbNm6tSpk9atW6fXXntN8+bNa1CNAACgaalzALrpppv073//W+Hh4Ro7dqzuvvtuXXnllRddwKhRo3T06FFNmzZNBQUF6tOnj7Kzsx0XOufn5zsdzRk0aJCysrL02GOPaerUqeratatWrFihHj16OPosXbpU6enpGjNmjI4fP65OnTrpqaee0r333nvR9QIAAN9X5wAUGBiov//97/rd734nf39/txaRmpqq1NRUl4+tXbu2WtuIESMc30XkSmRkpJYsWeKu8gAAQBNT5wDkDZ/uAgAAcIcGXwQNAADgqwhAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAADAcghAAIAmKXrKKrNLgBcjAAFoMviFB6CuCEAAAMByCEAAAMByCEDwOpzGAAB4GgEIAABYDgEIAABYDgEIAABYjlcEoAULFig6OlrBwcGKi4vT5s2ba+3/9ttvq1u3bgoODlbPnj21evXqan327t2rm2++WWFhYWrevLkGDhyo/Px8Tw0BAAD4ENMD0LJly5SWlqbp06dr+/bt6t27txITE1VUVOSy/8aNGzV69GiNGzdOO3bsUFJSkpKSkrRr1y5Hny+++ELXXHONunXrprVr1+qzzz7T448/ruDg4MYaFgAA8GKmB6B58+Zp/PjxSklJUUxMjBYuXKiQkBAtXrzYZf/nnntOQ4cO1eTJk9W9e3c98cQT6tevn+bPn+/o8+ijj+q3v/2tZs+erb59++qKK67QzTffrDZt2jTWsAAAgBcLMHPlZ8+e1bZt25Senu5o8/PzU0JCgvLy8lw+Jy8vT2lpaU5tiYmJWrFihSSpsrJSq1at0sMPP6zExETt2LFDnTt3Vnp6upKSklwus6ysTGVlZY77JSUlkqTy8nKVl5dfxAjREHZ/w+vn3RdqtCJv2i7eVEtjsfsbjtveMHYztoEVt7s3qc/c2wzDMC7czTOOHDmi9u3ba+PGjYqPj3e0P/zww1q3bp02bdpU7TlBQUF69dVXNXr0aEfbiy++qJkzZ6qwsFAFBQVq27atQkJC9OSTT+q//uu/lJ2dralTp2rNmjUaPHhwtWXOmDFDM2fOrNaelZWlkJAQN40WAAB4UmlpqW6//XYVFxcrNDS01r6mHgHyhMrKSknSLbfcogcffFCS1KdPH23cuFELFy50GYDS09OdjiqVlJQoKipKQ4YMueAEwn16zHhfu2YkOv71Zr5QoxV503bxploaS48Z7ztue8PYzdgGVtzu3qTqDE5dmBqAwsPD5e/vr8LCQqf2wsJCRUZGunxOZGRkrf3Dw8MVEBCgmJgYpz7du3fXRx995HKZdrtddru9WntgYKACAwPrPB5cnLIKmwIDAx3/ejNfqNGKvGm7eFMtjaWswua47Q1jN2MbWHG7e5P6zL2pF0EHBQWpf//+ys3NdbRVVlYqNzfX6ZTYueLj4536S1JOTo6jf1BQkAYOHKj9+/c79Tlw4IA6derk5hEAAABfZPopsLS0NCUnJ2vAgAGKjY1VZmamTp8+rZSUFEnS2LFj1b59e2VkZEiSJk6cqMGDB2vu3LkaNmyYli5dqq1bt2rRokWOZU6ePFmjRo3Stdde67gG6N1339XatWvNGCIAAPAypgegUaNG6ejRo5o2bZoKCgrUp08fZWdnKyIiQpKUn58vP79fDlQNGjRIWVlZeuyxxzR16lR17dpVK1asUI8ePRx9/vCHP2jhwoXKyMjQAw88oCuvvFL/+Mc/dM011zT6+AAAgPcxPQBJUmpqqlJTU10+5uqozYgRIzRixIhal3n33Xfr7rvvdkd5AACgiTH9ixABAAAaGwEIAABYDgEIAABYDgEIXiV6yiqzSwAAWAABCAAAWA4BCABwUThyC19EAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAAJZDAAIAoB741FvTQAACAMCNCEi+gQAEAAAshwAEr8X/ogAAnkIAAuqJYAYAvo8ABAAALIcABAAALIcABAAALIcABAAALIcABAAALIcABADARfLWT4d6a13egAAEAAAshwAEr8b/XgAAnkAAAtCkEJoB1AUBCADQ5BCEcSEEIAAAYDkEIAAAYDkEIABAg3GqCb6KAAQAACyHAAQAQBPHkbrqvCIALViwQNHR0QoODlZcXJw2b95ca/+3335b3bp1U3BwsHr27KnVq1fX2Pfee++VzWZTZmamm6sGANSGX7rwZqYHoGXLliktLU3Tp0/X9u3b1bt3byUmJqqoqMhl/40bN2r06NEaN26cduzYoaSkJCUlJWnXrl3V+i5fvlyffPKJ2rVr5+lhAAAAH2J6AJo3b57Gjx+vlJQUxcTEaOHChQoJCdHixYtd9n/uuec0dOhQTZ48Wd27d9cTTzyhfv36af78+U79Dh8+rPvvv19vvPGGAgMDG2MoAADAR5gagM6ePatt27YpISHB0ebn56eEhATl5eW5fE5eXp5Tf0lKTEx06l9ZWak777xTkydP1lVXXeWZ4gEAgM8KMHPlx44dU0VFhSIiIpzaIyIitG/fPpfPKSgocNm/oKDAcf+ZZ55RQECAHnjggTrVUVZWprKyMsf9kpISSVJ5ebnKy8vrtAxcPLu/4bhdXl7uuO9t28Bb64J3bRu7v+EVdXjauXPu6jVs1hx4cl9wNa6qNm/aByXnurylJk+qzxhthmEYF+7mGUeOHFH79u21ceNGxcfHO9offvhhrVu3Tps2bar2nKCgIL366qsaPXq0o+3FF1/UzJkzVVhYqG3btmnYsGHavn2749qf6OhoTZo0SZMmTXJZx4wZMzRz5sxq7VlZWQoJCbnIUQIAgMZQWlqq22+/XcXFxQoNDa21r6lHgMLDw+Xv76/CwkKn9sLCQkVGRrp8TmRkZK39N2zYoKKiInXs2NHxeEVFhR566CFlZmbq66+/rrbM9PR0paWlOe6XlJQoKipKQ4YMueAEwn16zHjfcXvXjETH/V0zEs0qySVvrQvetW16zHjfK+rwtHPn3NVr2Kw58OS+4GpcVW3etA9KznV5S02eVHUGpy5MDUBBQUHq37+/cnNzlZSUJOnn63dyc3OVmprq8jnx8fHKzc11OpqTk5PjOIJ05513urxG6M4771RKSorLZdrtdtnt9mrtgYGBXEDdiMoqbI7bgYGBjvvetg28tS5417Ypq7B5RR2edu6cu3oNmzUHntwXXI2rqs2b9kHJuS5vqcmT6jNGUwOQJKWlpSk5OVkDBgxQbGysMjMzdfr0aUdYGTt2rNq3b6+MjAxJ0sSJEzV48GDNnTtXw4YN09KlS7V161YtWrRIktS6dWu1bt3aaR2BgYGKjIzUlVde2biDAwAAXsn0ADRq1CgdPXpU06ZNU0FBgfr06aPs7GzHhc75+fny8/vlw2qDBg1SVlaWHnvsMU2dOlVdu3bVihUr1KNHD7OGAAAAfIzpAUiSUlNTazzltXbt2mptI0aM0IgRI+q8fFfX/QAAAOsy/YsQAQAAGhsBCAAAWA4BCADQIFb8Y6dWHHNTRQACAACWQwAC4Bb8zxiALyEAAQAAyyEAAQAAyyEAAQCaNE7PwhUCEACfxy84APVFAAK/PAAAlkMAAgAAlkMAAgAAlkMAAnBBFzpNymlUAL6GAASgTgg5AJoSAhAAALAcAhC8Xn2OPHCUAgBQFwQgNBmEH8B6eN2joQhAaBJ4EwQA1EeA2QUAF4PgAwBoCI4AQZJvBglfrBkA4B0IQF6GX+oAAHgeAciLEH4A4OLxXoq6IAB5CV6wvodtBgC+iwCEJolwAgCoDQEIPomAYw7mHUBTQQACAACWQwACAACWQwDyUpxqgDuwH3kntgtgPgIQ6s1X3rx9pU5v5gtz6As1uuKrdbsb8wCzEIDQILxpeb/G2EZm7gdNYR9sCmO4GOeO35fnwpdrtzICkMl87YXja/XCM8zeD8xev9W5Y/5dLaMpbdemNJamigAE0/AGgfpgf4G7sU+5l6/Np1cEoAULFig6OlrBwcGKi4vT5s2ba+3/9ttvq1u3bgoODlbPnj21evVqx2Pl5eV65JFH1LNnTzVv3lzt2rXT2LFjdeTIEU8Po8mKnrLKozu2r71ofA3z612a+pEPwFeYHoCWLVumtLQ0TZ8+Xdu3b1fv3r2VmJiooqIil/03btyo0aNHa9y4cdqxY4eSkpKUlJSkXbt2SZJKS0u1fft2Pf7449q+fbveeecd7d+/XzfffHNjDqtOLvSm5w1vit5Qw8Xwhvq9oQZPaKrjsgqrbz+rjx9eEIDmzZun8ePHKyUlRTExMVq4cKFCQkK0ePFil/2fe+45DR06VJMnT1b37t31xBNPqF+/fpo/f74kKSwsTDk5ORo5cqSuvPJK/frXv9b8+fO1bds25efnN+bQAJ/mrb8gvLWui2XWuJrqfAIXYmoAOnv2rLZt26aEhARHm5+fnxISEpSXl+fyOXl5eU79JSkxMbHG/pJUXFwsm82mVq1auaVuoC74xQLUH68bNJYAM1d+7NgxVVRUKCIiwqk9IiJC+/btc/mcgoICl/0LCgpc9j9z5oweeeQRjR49WqGhoS77lJWVqayszHG/pKRE0s/XE5WXl9d5PPVl9zcc66m6ff59T67fVR01PXZ+Xe6oze5vOJZZ2xy4Wte5j53P3XWer67LPn98je1i56Au++f5912tp8eM9yVJu2Yk1ruG8+s5f91XPvov2f3rVocr7qrNlZq2+/n7bmO/3s+to6H7Z11fs7Ut213vLa7WUZc6zp3zHjPer/M+4Gpb1fZaMVtjvg+Z9V53rvqs32YYRs2/STzsyJEjat++vTZu3Kj4+HhH+8MPP6x169Zp06ZN1Z4TFBSkV199VaNHj3a0vfjii5o5c6YKCwud+paXl2v48OH69ttvtXbt2hoD0IwZMzRz5sxq7VlZWQoJCWno8AAAQCMqLS3V7bffruLi4hp/51cx9QhQeHi4/P39qwWXwsJCRUZGunxOZGRknfqXl5dr5MiR+uabb/Thhx/WOhHp6elKS0tz3C8pKVFUVJSGDBlywQlsqKr/eUo//++zpvue+J9pTbW4WteF6rzY9VYts7Y5cLWucx87n7vrPN+Flm3mtqytjoY+vy7bpj77UEPUVMu5GjLXnt5PLjQfVev1ZB011Xbuuuu7zrq+ZmtbtrveW1yt40J11KfOmup2tTwztuWFnP8+2xjrMlPVGZy6MDUABQUFqX///srNzVVSUpIkqbKyUrm5uUpNTXX5nPj4eOXm5mrSpEmOtpycHKcjSFXh5+DBg1qzZo1at25dax12u112u71ae2BgoAIDA+s/sDooq7A5raem+10f/0BfzxrmkRrOr+XcsUZPWaWvZw27YJ0Xu96qZdY2B67Wde5j53N3nee70LJrGoen9qWaXOwcnFt3XffX89fz8/UcF78taqrlXA2Za0/vJxeaj6r1erKOmmo7d931XWddX7O1Ldtd7y2u1nGhOupTZ011u1qeGdvyQs5/n22MdZmpPus3/VNgaWlpevnll/Xqq69q7969+tOf/qTTp08rJSVFkjR27Filp6c7+k+cOFHZ2dmaO3eu9u3bpxkzZmjr1q2OwFReXq4//vGP2rp1q9544w1VVFSooKBABQUFOnv2rCljbMq4YBE1Yd/wHb66rdxZt6/OARrO1CNAkjRq1CgdPXpU06ZNU0FBgfr06aPs7GzHhc75+fny8/slpw0aNEhZWVl67LHHNHXqVHXt2lUrVqxQjx49JEmHDx/WypUrJUl9+vRxWteaNWt03XXXNcq4AADVVR1dbioITr7L9AAkSampqTWe8lq7dm21thEjRmjEiBEu+0dHR8vE67qBGjW1N/7a1PRLwUpzAMC7mX4KDKgvM/7HZbX/5VltvJ7CPMJM7H+1IwABbsKbje+w8ra62LFbee7QtBCA4MAbm2u+Ni++Vq9VsF28H9vIWghAQB3x5oimrDH2b15D8CYEIFw03tRgRez3dcM8wVsRgAA34E2+aXDHdvSWZQCoHQGoiYiesoo3TeD/11ivBV5zuFi8d5uHAARL4A3Ge+bAW+qwEubcO7FdzEUAQjWN+aK02huAp8drtfkEqjSFIym+Xr+vIQDBLaz8wrXy2H2RGd+Dwz5Sfxeas3Mf97X59bV6myoCkIXxIoQr7BeA59Qn2MGzCEAAvJpVfyFYddy+giOBvo8ABMvwljcfd9dRtTxvGR8A+AICEODDfDX0eHPd3lyb2awwN1YYI35GAEKj4w0GTYkvX4x7Pl+vv6kwezuYvf7GQgACfJQnrkGwyhuflfjyNvXl2n2VlU6pE4AAAPAwXwgU59foiZq9aR4IQIAJvOlNAO7R1H9ZoOmx+v5FAEKjMvsFZ/b63aWpjAOAuax0yut8BCAfYcWd02zeOufeWld9mTGOuq6zqczxuZrimFAztveFEYAAAECNmmqYIgABPsQdb0RN9c0MP6v6o6BsZ+/hjdvCG2tqbAQgi/Lm0w8wh7dtH2+rR/LOmtzN2y7m5r0KnkIAAlzwtTdAX6v3QpraeBoDcwZPaor7FwEITpriTg7fwj4Ib8SRqKaHANQE8aIBAKB2BKAmwJsCjzfVAgBATQhAgAhu8G3u3n95PXgPd26Li11Wbc+vy7K9bb8iAPkQd+08nMuunTfU6g01WB3bAGjaCEDwKVb9pWTVcePC2Dc8g3lt+ghATRQv3tp58/x4c20wB/uEtdVn+3vDvuINNdQFAcjH+cKO5gs1msUXz5tbldW2Q1Mcb1Mckze40Lx66zeTe0UAWrBggaKjoxUcHKy4uDht3ry51v5vv/22unXrpuDgYPXs2VOrV692etwwDE2bNk1t27ZVs2bNlJCQoIMHD3pyCKaoy05nBk+ttzHGY/aL9Pz1e7Ies8eK+jl3e7Ht6s+sb6NuzG3FflE/pgegZcuWKS0tTdOnT9f27dvVu3dvJSYmqqioyGX/jRs3avTo0Ro3bpx27NihpKQkJSUladeuXY4+s2fP1vPPP6+FCxdq06ZNat68uRITE3XmzJnGGpbH+cqO7it1Sk0vMOKXuW3oHHvbtmnMgOzu9fjyhzi8hTv+zps3bUuzmR6A5s2bp/HjxyslJUUxMTFauHChQkJCtHjxYpf9n3vuOQ0dOlSTJ09W9+7d9cQTT6hfv36aP3++pJ+P/mRmZuqxxx7TLbfcol69eum1117TkSNHtGLFikYcmWc0ZMcz448j+sILxJtq9KZaGtvFhpS6Lt8sTXVcjY1Pr9ausWu9mNNe3nJKzNQAdPbsWW3btk0JCQmONj8/PyUkJCgvL8/lc/Ly8pz6S1JiYqKj/1dffaWCggKnPmFhYYqLi6txmbAub3gRmsndb0RNcT6b4pjqytvG7m31mM3s+TB7/RcrwMyVHzt2TBUVFYqIiHBqj4iI0L59+1w+p6CgwGX/goICx+NVbTX1OV9ZWZnKysoc94uLiyVJx48fV3l5eT1GVHcBP5123P7+++8v6v65vGlZjVWnJ5fNHDROnV3+5y0FmFyn2XPgrXU2dNs0lW1VNX5vq/Pc147k/MvcG+usadnudvLkSUk/nw26IMNEhw8fNiQZGzdudGqfPHmyERsb6/I5gYGBRlZWllPbggULjDZt2hiGYRgff/yxIck4cuSIU58RI0YYI0eOdLnM6dOnG5L44Ycffvjhh58m8HPo0KELZhBTjwCFh4fL399fhYWFTu2FhYWKjIx0+ZzIyMha+1f9W1hYqLZt2zr16dOnj8tlpqenKy0tzXG/srJSx48fV+vWrWWz2eo9rtqUlJQoKipKhw4dUmhoqFuXDea3MTDHnsX8eh5z7Flmzq9hGDp58qTatWt3wb6mBqCgoCD1799fubm5SkpKkvRz+MjNzVVqaqrL58THxys3N1eTJk1ytOXk5Cg+Pl6S1LlzZ0VGRio3N9cReEpKSrRp0yb96U9/crlMu90uu93u1NaqVauLGtuFhIaG8sLzIObX85hjz2J+PY859iyz5jcsLKxO/UwNQJKUlpam5ORkDRgwQLGxscrMzNTp06eVkpIiSRo7dqzat2+vjIwMSdLEiRM1ePBgzZ07V8OGDdPSpUu1detWLVq0SJJks9k0adIkPfnkk+ratas6d+6sxx9/XO3atXOELAAAYG2mB6BRo0bp6NGjmjZtmgoKCtSnTx9lZ2c7LmLOz8+Xn98vH1YbNGiQsrKy9Nhjj2nq1Knq2rWrVqxYoR49ejj6PPzwwzp9+rTuuecenThxQtdcc42ys7MVHBzc6OMDAADex2YYdblUGu5SVlamjIwMpaenVzvthovH/Hoec+xZzK/nMcee5SvzSwACAACWY/o3QQMAADQ2AhAAALAcAhAAALAcAhAAALAcAlAjWrBggaKjoxUcHKy4uDht3rzZ7JJ8QkZGhgYOHKiWLVuqTZs2SkpK0v79+536nDlzRhMmTFDr1q3VokULDR8+vNo3hufn52vYsGEKCQlRmzZtNHnyZP3000+NORSfMGvWLMf3aVVhfi/e4cOHdccdd6h169Zq1qyZevbsqa1btzoeNwxD06ZNU9u2bdWsWTMlJCTo4MGDTss4fvy4xowZo9DQULVq1Urjxo3TqVOnGnsoXqeiokKPP/64OnfurGbNmumKK67QE0884fT3oJjf+lm/fr1+//vfq127drLZbFqxYoXT4+6az88++0y/+c1vFBwcrKioKM2ePdvTQ3MaBBrB0qVLjaCgIGPx4sXG7t27jfHjxxutWrUyCgsLzS7N6yUmJhpLliwxdu3aZezcudP47W9/a3Ts2NE4deqUo8+9995rREVFGbm5ucbWrVuNX//618agQYMcj//0009Gjx49jISEBGPHjh3G6tWrjfDwcCM9Pd2MIXmtzZs3G9HR0UavXr2MiRMnOtqZ34tz/Phxo1OnTsZdd91lbNq0yfjyyy+N999/3/j8888dfWbNmmWEhYUZK1asMD799FPj5ptvNjp37mz8+OOPjj5Dhw41evfubXzyySfGhg0bjC5duhijR482Y0he5amnnjJat25t/Otf/zK++uor4+233zZatGhhPPfcc44+zG/9rF692nj00UeNd955x5BkLF++3Olxd8xncXGxERERYYwZM8bYtWuX8eabbxrNmjUz/vrXvzbKGAlAjSQ2NtaYMGGC435FRYXRrl07IyMjw8SqfFNRUZEhyVi3bp1hGIZx4sQJIzAw0Hj77bcdffbu3WtIMvLy8gzD+PnF7OfnZxQUFDj6vPTSS0ZoaKhRVlbWuAPwUidPnjS6du1q5OTkGIMHD3YEIOb34j3yyCPGNddcU+PjlZWVRmRkpPHss8862k6cOGHY7XbjzTffNAzDMPbs2WNIMrZs2eLo89577xk2m804fPiw54r3AcOGDTPuvvtup7Zbb73VGDNmjGEYzO/FOj8AuWs+X3zxReOSSy5xeo945JFHjCuvvNLDI/oZp8AawdmzZ7Vt2zYlJCQ42vz8/JSQkKC8vDwTK/NNxcXFkqRLL71UkrRt2zaVl5c7zW+3bt3UsWNHx/zm5eWpZ8+ejm8Yl6TExESVlJRo9+7djVi995owYYKGDRvmNI8S8+sOK1eu1IABAzRixAi1adNGffv21csvv+x4/KuvvlJBQYHTHIeFhSkuLs5pjlu1aqUBAwY4+iQkJMjPz0+bNm1qvMF4oUGDBik3N1cHDhyQJH366af66KOPdNNNN0lift3NXfOZl5ena6+9VkFBQY4+iYmJ2r9/v3744QePj8P0P4VhBceOHVNFRYXTLwdJioiI0L59+0yqyjdVVlZq0qRJuvrqqx1//qSgoEBBQUHV/oBtRESECgoKHH1czX/VY1a3dOlSbd++XVu2bKn2GPN78b788ku99NJLSktL09SpU7VlyxY98MADCgoKUnJysmOOXM3huXPcpk0bp8cDAgJ06aWXWn6Op0yZopKSEnXr1k3+/v6qqKjQU089pTFjxkgS8+tm7prPgoICde7cudoyqh675JJLPFK/ox6PLh1wswkTJmjXrl366KOPzC6lyTh06JAmTpyonJwc/l6eh1RWVmrAgAF6+umnJUl9+/bVrl27tHDhQiUnJ5tcne9766239MYbbygrK0tXXXWVdu7cqUmTJqldu3bML2rEKbBGEB4eLn9//2qfmiksLFRkZKRJVfme1NRU/etf/9KaNWvUoUMHR3tkZKTOnj2rEydOOPU/d34jIyNdzn/VY1a2bds2FRUVqV+/fgoICFBAQIDWrVun559/XgEBAYqIiGB+L1Lbtm0VExPj1Na9e3fl5+dL+mWOanuPiIyMVFFRkdPjP/30k44fP275OZ48ebKmTJmi2267TT179tSdd96pBx98UBkZGZKYX3dz13ya/b5BAGoEQUFB6t+/v3Jzcx1tlZWVys3NVXx8vImV+QbDMJSamqrly5frww8/rHbItH///goMDHSa3/379ys/P98xv/Hx8frPf/7j9ILMyclRaGhotV9MVnPDDTfoP//5j3bu3On4GTBggMaMGeO4zfxenKuvvrraVzccOHBAnTp1kiR17txZkZGRTnNcUlKiTZs2Oc3xiRMntG3bNkefDz/8UJWVlYqLi2uEUXiv0tJS+fk5/zrz9/dXZWWlJObX3dw1n/Hx8Vq/fr3Ky8sdfXJycnTllVd6/PSXJD4G31iWLl1q2O1245VXXjH27Nlj3HPPPUarVq2cPjUD1/70pz8ZYWFhxtq1a43vvvvO8VNaWuroc++99xodO3Y0PvzwQ2Pr1q1GfHy8ER8f73i86mPaQ4YMMXbu3GlkZ2cbl112GR/TrsG5nwIzDOb3Ym3evNkICAgwnnrqKePgwYPGG2+8YYSEhBivv/66o8+sWbOMVq1aGf/85z+Nzz77zLjllltcfqy4b9++xqZNm4yPPvrI6Nq1q2U/pn2u5ORko3379o6Pwb/zzjtGeHi48fDDDzv6ML/1c/LkSWPHjh3Gjh07DEnGvHnzjB07dhjffPONYRjumc8TJ04YERERxp133mns2rXLWLp0qRESEsLH4JuiF154wejYsaMRFBRkxMbGGp988onZJfkESS5/lixZ4ujz448/Gvfdd59xySWXGCEhIcYf/vAH47vvvnNaztdff23cdNNNRrNmzYzw8HDjoYceMsrLyxt5NL7h/ADE/F68d9991+jRo4dht9uNbt26GYsWLXJ6vLKy0nj88ceNiIgIw263GzfccIOxf/9+pz7ff/+9MXr0aKNFixZGaGiokZKSYpw8ebIxh+GVSkpKjIkTJxodO3Y0goODjcsvv9x49NFHnT5ezfzWz5o1a1y+7yYnJxuG4b75/PTTT41rrrnGsNvtRvv27Y1Zs2Y11hANm2Gc81WZAAAAFsA1QAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAAwHIIQAAsxWazacWKFWaXAcBkBCAAPuOuu+5SUlKS2WUAaAIIQAAAwHIIQAB80nXXXacHHnhADz/8sC699FJFRkZqxowZTn0OHjyoa6+9VsHBwYqJiVFOTk615Rw6dEgjR45Uq1atdOmll+qWW27R119/LUnat2+fQkJClJWV5ej/1ltvqVmzZtqzZ48nhwfAwwhAAHzWq6++qubNm2vTpk2aPXu2/vznPztCTmVlpW699VYFBQVp06ZNWrhwoR555BGn55eXlysxMVEtW7bUhg0b9PHHH6tFixYaOnSozp49q27dumnOnDm67777lJ+fr2+//Vb33nuvnnnmGcXExJgxZABuwh9DBeAz7rrrLp04cUIrVqzQddddp4qKCm3YsMHxeGxsrK6//nrNmjVLH3zwgYYNG6ZvvvlG7dq1kyRlZ2frpptu0vLly5WUlKTXX39dTz75pPbu3SubzSZJOnv2rFq1aqUVK1ZoyJAhkqTf/e53KikpUVBQkPz9/ZWdne3oD8A3BZhdAAA0VK9evZzut23bVkVFRZKkvXv3KioqyhF+JCk+Pt6p/6effqrPP/9cLVu2dGo/c+aMvvjiC8f9xYsX61e/+pX8/Py0e/duwg/QBBCAAPiswMBAp/s2m02VlZV1fv6pU6fUv39/vfHGG9Ueu+yyyxy3P/30U50+fVp+fn767rvv1LZt24YXDcArEIAANEndu3fXoUOHnALLJ5984tSnX79+WrZsmdq0aaPQ0FCXyzl+/LjuuusuPfroo/ruu+80ZswYbd++Xc2aNfP4GAB4DhdBA2iSEhIS9Ktf/UrJycn69NNPtWHDBj366KNOfcaMGaPw8HDdcsst2rBhg7766iutXbtWDzzwgL799ltJ0r333quoqCg99thjmjdvnioqKvQ///M/ZgwJgBsRgAA0SX5+flq+fLl+/PFHxcbG6r//+7/11FNPOfUJCQnR+vXr1bFjR916663q3r27xo0bpzNnzig0NFSvvfaaVq9erf/7v/9TQECAmjdvrtdff10vv/yy3nvvPZNGBsAd+BQYAACwHI4AAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAyyEAAQAAy/n/AMVT4K0ptCNmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 비정상 점수 그래프로 표시하기\n",
    "\n",
    "# x축 인덱스 생성\n",
    "indices = list(range(len(anomaly_scores)))\n",
    "\n",
    "# 막대 그래프 그리기\n",
    "plt.bar(indices, anomaly_scores)\n",
    "plt.title('List Values')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a40247b9-72f6-41ad-a811-7666b6a9c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame 분할 있음\n",
    "import cv2\n",
    "out_img_list = []\n",
    "out_index = 0\n",
    "frame_index = 0\n",
    "frame_cnt = 0\n",
    "is_detection = False\n",
    "threshold = 0.0025\n",
    "result_video = cv2.VideoCapture(video_path)\n",
    "width = int(result_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(result_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while result_video.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = result_video.read()\n",
    "\n",
    "    if success:\n",
    "        cv2.rectangle(frame, (45, 25), (800, 60), (255, 255, 255), -1)\n",
    "        if out_index < len(anomaly_scores):\n",
    "            if anomaly_scores[out_index] < threshold:\n",
    "                if frame_cnt == 0:\n",
    "                    frame_index = out_index\n",
    "                    is_detection = True\n",
    "        if is_detection:\n",
    "            if frame_cnt < 72:\n",
    "                info = f'detection! -> {test_data_list[frame_index][0]}'\n",
    "                cv2.putText(frame, info, (45, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), thickness=3)\n",
    "                info = f'Swing|F:{test_data_list[frame_index][1][0]:.1%}, N:{test_data_list[frame_index][1][1]:.1%}, D:{test_data_list[frame_index][1][2]:.1%}, Si:{test_data_list[frame_index][1][3]:.1%}, T:{test_data_list[frame_index][1][4]:.1%}'\n",
    "                cv2.putText(frame, info, (45, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), thickness=3)\n",
    "                info = f'Swing|Z:{test_data_list[frame_index][1][5]:.1%}, M:{test_data_list[frame_index][1][6]:.1%}, A:{test_data_list[frame_index][1][7]:.1%}, R:{test_data_list[frame_index][1][8]:.1%}, Sh:{test_data_list[frame_index][1][9]:.1%}'\n",
    "                cv2.putText(frame, info, (45, 250), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), thickness=3)\n",
    "                frame_cnt += 1\n",
    "            else:\n",
    "                frame_cnt = 0\n",
    "                is_detection = False\n",
    "        out_img_list.append(frame)\n",
    "        out_index += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "result_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ac15b8d-9112-4ff9-ba52-171980cb7633",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './test.mp4'\n",
    "fourcc =  cv2.VideoWriter_fourcc(*'DIVX')\n",
    "fps = 30\n",
    "isColor = True\n",
    "out = cv2.VideoWriter(filename, fourcc, fps, (width, height), isColor)\n",
    "for out_img in out_img_list:\n",
    "    out.write(out_img)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e4d26b7-c202-4af4-a888-251d4e8be831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame 분할 없음\n",
    "import cv2\n",
    "out_img_list = []\n",
    "out_index = 0\n",
    "threshold = 0.004\n",
    "result_video = cv2.VideoCapture(video_path)\n",
    "width = int(result_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(result_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while result_video.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = result_video.read()\n",
    "\n",
    "    if success:\n",
    "        if out_index < len(anomaly_scores):\n",
    "            if anomaly_scores[out_index] < threshold:\n",
    "                info = f'detection! -> {test_data_list[out_index][0]}'\n",
    "                cv2.putText(frame, info, (45, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), thickness=3)\n",
    "        out_img_list.append(frame)\n",
    "        out_index = out_index + 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "result_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cac3f06-ea24-473a-a624-45de2f7e758d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
