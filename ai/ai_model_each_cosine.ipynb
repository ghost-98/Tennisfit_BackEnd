{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c708020-642c-43f7-9a7c-2baf52805041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 사용 가능\n"
     ]
    }
   ],
   "source": [
    "# 각 관절끼리 각각 cosine similarity 검출 (실패)\n",
    "import torch\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = 'cuda:0'\n",
    "    print('GPU 사용 가능')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('GPU 사용 불가')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d0d84098-6122-4101-a039-025ba6596694",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from model.extract_user_dataset import extract_user_dataset\n",
    "\n",
    "video_path = './video/test_video3.mp4'\n",
    "#test_dataset = extract_user_dataset(video_path)\n",
    "import numpy as np\n",
    "test_dataset = np.load('./video/test_video3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae14064-3bfd-41a7-a0a5-deef34be9280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader # Pytorch에서 데이터를 불러오고, 전처리하는 클래스\n",
    "\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, seq_data):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        for dic in seq_data:\n",
    "            self.X.append(dic['value'])\n",
    "            self.y.append(dic['key'])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.X[index]\n",
    "        label = self.y[index]\n",
    "        return torch.Tensor(np.array(data)), torch.tensor(np.array(int(label)))\n",
    "\n",
    "    def __len__(self):\n",
    "            return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc34fa7e-e08d-4907-8e85-646edaaf11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader # Pytorch에서 데이터를 불러오고, 전처리하는 클래스\n",
    "\n",
    "class AnomalyDetectionDataset(Dataset):\n",
    "    def __init__(self, seq_data):\n",
    "        self.dataset = []\n",
    "        for data in seq_data:\n",
    "            self.dataset.append(data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.dataset[index]\n",
    "        return torch.Tensor(np.array(data))\n",
    "        \n",
    "    def __len__(self):\n",
    "            return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d44b404-82c2-4572-b466-3c4e185d2097",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM_model, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=100, hidden_size = 172, num_layers=1, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=172, hidden_size = 256, num_layers=1, batch_first=True)\n",
    "        #self.lstm3 = nn.LSTM(input_size=256, hidden_size = 512, num_layers=1, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        #self.lstm4 = nn.LSTM(input_size=512, hidden_size = 256, num_layers=1, batch_first=True)\n",
    "        self.lstm5 = nn.LSTM(input_size=256, hidden_size = 128, num_layers=1, batch_first=True)\n",
    "        self.lstm6 = nn.LSTM(input_size=128, hidden_size = 64, num_layers=1, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.lstm7 = nn.LSTM(input_size=64, hidden_size = 32, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(32, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        #x, _ = self.lstm3(x)\n",
    "        x = self.dropout1(x)\n",
    "        #x, _ = self.lstm4(x)\n",
    "        x, _ = self.lstm5(x)\n",
    "        x, _ = self.lstm6(x)\n",
    "        x = self.dropout2(x)\n",
    "        x, _ = self.lstm7(x)\n",
    "        x = self.fc(x[:,-1,:])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "920148c6-0b9c-40a3-96c8-9ca3e3cc48af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size=100, hidden_size=50, num_layers=2):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,\n",
    "                            dropout=0.3, bidirectional=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs, (hidden, cell) = self.lstm(x)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        return (hidden, cell)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size=100, hidden_size=50, output_size=100, num_layers=2):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True,\n",
    "                            dropout=0.3, bidirectional=False)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        output, (hidden, cell) = self.lstm(x, hidden)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        prediction = self.fc(output)\n",
    "\n",
    "        return prediction, (hidden, cell)\n",
    "    \n",
    "## LSTM Auto Encoder\n",
    "class LSTMAutoEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 latent_dim: int,\n",
    "                 sequence_length: int=1,\n",
    "                 **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        :param input_dim: 변수 Tag 갯수\n",
    "        :param latent_dim: 최종 압축할 차원 크기\n",
    "        :param sequence length: sequence 길이\n",
    "        :param kwargs:\n",
    "        \"\"\"\n",
    "\n",
    "        super(LSTMAutoEncoder, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        if \"num_layers\" in kwargs:\n",
    "            num_layers = kwargs.pop(\"num_layers\")\n",
    "        else:\n",
    "            num_layers = 1\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=latent_dim,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.reconstruct_decoder = Decoder(\n",
    "            input_size=input_dim,\n",
    "            output_size=input_dim,\n",
    "            hidden_size=latent_dim,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "\n",
    "    def forward(self, src:torch.Tensor, **kwargs):\n",
    "        batch_size, sequence_length, var_length = src.size()\n",
    "\n",
    "        ## Encoder 넣기t\n",
    "        encoder_hidden = self.encoder(src)\n",
    "        \n",
    "        inv_idx = torch.arange(sequence_length - 1, -1, -1).long()\n",
    "        reconstruct_output = []\n",
    "        temp_input = torch.zeros((batch_size, 1, var_length), dtype=torch.float).to(src.device)\n",
    "        hidden = encoder_hidden\n",
    "        for t in range(sequence_length):\n",
    "            temp_input, hidden = self.reconstruct_decoder(temp_input, hidden)\n",
    "            reconstruct_output.append(temp_input)\n",
    "        reconstruct_output = torch.cat(reconstruct_output, dim=1)[:, inv_idx, :]\n",
    "        \n",
    "        return [reconstruct_output, src]\n",
    "\n",
    "    def loss_function(self,\n",
    "                      *args,\n",
    "                      **kwargs) -> dict:\n",
    "        recons = args[0]\n",
    "        input = args[1]\n",
    "        \n",
    "        ## MSE loss(Mean squared Error)\n",
    "        loss =F.mse_loss(recons, input)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11bb605c-d8e1-4e22-bcf9-4aa4046a645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 세팅\n",
    "import joblib\n",
    "\n",
    "classification_model = LSTM_model().to(device)\n",
    "anomaly_detection_model = LSTMAutoEncoder(input_dim=100, latent_dim=50, sequence_length=60, num_layers=4).to(device)\n",
    "\n",
    "# 모델 불러오기\n",
    "classification_model.load_state_dict(torch.load('./model/model_info/classification_model', map_location=device))\n",
    "anomaly_detection_model.load_state_dict(torch.load('./model/model_info/anomaly_detection_model', map_location=device))\n",
    "similarity_model = joblib.load('./model/model_info/similarity_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "47309fb6-6949-4a71-9de9-38ec09040993",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "classification_model.eval()\n",
    "anomaly_detection_model.eval()\n",
    "\n",
    "test_data = []\n",
    "classification_data = []\n",
    "anomaly_detection_data = []\n",
    "\n",
    "for data in test_dataset:\n",
    "    test_data.append(data)\n",
    "    classification_data.append({'key': 8, 'value': data})\n",
    "    anomaly_detection_data.append(data)\n",
    "\n",
    "classification_data = ClassificationDataset(classification_data)\n",
    "classification_data = DataLoader(classification_data)\n",
    "anomaly_detection_data = AnomalyDetectionDataset(anomaly_detection_data)\n",
    "anomaly_detection_data = DataLoader(anomaly_detection_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2ff95be5-c73c-42c8-87c5-44a649b54176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 545/545 [00:01<00:00, 393.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Classification 계산\n",
    "classification_list = []\n",
    "\n",
    "for data, label in tqdm(classification_data):\n",
    "    data = data.to(device)\n",
    "    with torch.no_grad():\n",
    "        result = classification_model(data)\n",
    "        result = F.softmax(result, dim=1)\n",
    "        out_result, out = torch.max(result, 1)\n",
    "        if out.item() == 0: \n",
    "            classification_list.append(['Forehand', out_result])\n",
    "        elif out.item() == 1: \n",
    "            classification_list.append(['Backhand', out_result])\n",
    "        elif out.item() == 2: \n",
    "            classification_list.append(['Backslice', out_result])\n",
    "        elif out.item() == 3: \n",
    "            classification_list.append(['ForeVolley', out_result])\n",
    "        elif out.item() == 4: \n",
    "            classification_list.append(['BackVolley', out_result])\n",
    "        elif out.item() == 5: \n",
    "            classification_list.append(['Smash', out_result])\n",
    "        elif out.item() == 6: \n",
    "            classification_list.append(['Serve', out_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9d91d7fa-21fd-43a6-b203-33f811d1aa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|                                                                                                                                                | 0/545 [00:00<?, ?it/s]C:\\Users\\yhjmi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Testing: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 545/545 [00:06<00:00, 77.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# data anomaly detection loss 계산하기\n",
    "anomaly_detection_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _data in tqdm(anomaly_detection_data, desc='Testing'):\n",
    "        data = _data.to(device)\n",
    "        predict_values = anomaly_detection_model(data)\n",
    "\n",
    "        ## MAE(Mean Absolute Error)로 계산\n",
    "        loss = F.l1_loss(predict_values[0], predict_values[1], reduce=False)\n",
    "        #loss = loss.sum(dim=2).sum(dim=1).cpu().numpy()\n",
    "        loss = loss.mean(dim=1).cpu().numpy()\n",
    "        anomaly_detection_list.append(loss)\n",
    "anomaly_detection_list = np.concatenate(anomaly_detection_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b8909275-2bfc-496f-a057-64a27d2aabb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 545/545 [00:00<00:00, 13975.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# 비정상 점수 계산\n",
    "\n",
    "# Reconstruction Error의 평균과 Covarinace 계산\n",
    "mean = np.mean(anomaly_detection_list, axis=0)\n",
    "std = np.cov(anomaly_detection_list.T)\n",
    "\n",
    "class Anomaly_Calculator:\n",
    "    def __init__(self, mean:np.array, std:np.array):\n",
    "        assert mean.shape[0] == std.shape[0] and mean.shape[0] == std.shape[1], '평균과 분산의 차원이 똑같아야 합니다.'\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    \n",
    "    def __call__(self, recons_error:np.array):\n",
    "        x = (recons_error-self.mean)\n",
    "        return np.matmul(np.matmul(x, self.std), x.T)\n",
    "\n",
    "anomaly_calculator = Anomaly_Calculator(mean, std)\n",
    "\n",
    "anomaly_scores = []\n",
    "for temp_loss in tqdm(anomaly_detection_list):\n",
    "    temp_score = anomaly_calculator(temp_loss)\n",
    "    anomaly_scores.append(temp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c17b9a6a-b916-47d4-8d7b-98b659114e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 비정상 점수 그래프로 표시하기\n",
    "\n",
    "# x축 인덱스 생성\n",
    "indices = list(range(len(anomaly_scores)))\n",
    "\n",
    "# 막대 그래프 그리기\n",
    "plt.bar(indices, anomaly_scores)\n",
    "plt.title('List Values')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "417753c4-939b-480b-a7f3-b9a82719328f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tslearn.metrics import dtw\n",
    "from scipy.spatial import procrustes\n",
    "    \n",
    "centroids = similarity_model.cluster_centers_\n",
    "\n",
    "remove_padding_centroids = []\n",
    "\n",
    "for centroid in centroids:\n",
    "    remove_padding_centroids.append(np.array([i for i in centroid if i[0] != 0]))\n",
    "\n",
    "similarity_cos = []\n",
    "similarity_procrustes = []\n",
    "\n",
    "similarity_cos_cluster = []\n",
    "similarity_procrustes_cluster = []\n",
    "\n",
    "# 관절 가중치\n",
    "joint_point_weight = []\n",
    "for i in range(25):\n",
    "    if i < 15:\n",
    "        joint_point_weight.append(0.05)\n",
    "    else:\n",
    "        joint_point_weight.append(0.025)\n",
    "\n",
    "temp_index = 0\n",
    "for seq_data in test_data:\n",
    "    distances_cos = []\n",
    "    distances_cos1 = []\n",
    "    # 각 클러스터 중심과의 코사인 거리 계산\n",
    "    for centroid in remove_padding_centroids:\n",
    "        joint_cos = []\n",
    "        for data in seq_data[:len(centroid)]:\n",
    "            joint_data = []\n",
    "            for i in range(25):\n",
    "                joint_data.append([data[i * 4], data[i * 4 + 1], data[i * 4 + 2], data[i * 4 + 3]])\n",
    "        for data in centroid:\n",
    "            cluster_joint_data = []\n",
    "            for i in range(25):\n",
    "                cluster_joint_data.append([data[i * 4], data[i * 4 + 1], data[i * 4 + 2], data[i * 4 + 3]])\n",
    "        for i in range(25):\n",
    "            joint_cos.append(cosine_similarity([joint_data[i]], [cluster_joint_data[i]])[0][0] * joint_point_weight[i])\n",
    "        distances_cos.append((sum(joint_cos) + 1) / 2)\n",
    "        distances_cos1.append((cosine_similarity(np.array(seq_data[:len(centroid)]).flatten().reshape(1, -1), centroid.flatten().reshape(1, -1))))\n",
    "    \n",
    "    closest_cluster = np.argmax(distances_cos)\n",
    "    similarity_cos.append(distances_cos)\n",
    "    if closest_cluster == 4 or closest_cluster == 9:\n",
    "        similarity_cos_cluster.append('Forehand')\n",
    "    elif closest_cluster == 2 or closest_cluster == 5:\n",
    "        similarity_cos_cluster.append('Backhand')\n",
    "    elif closest_cluster == 10 or closest_cluster == 12:\n",
    "        similarity_cos_cluster.append('Backslice')\n",
    "    elif closest_cluster == 0 or closest_cluster == 3:\n",
    "        similarity_cos_cluster.append('ForeVolley')\n",
    "    elif closest_cluster == 7 or closest_cluster == 8:\n",
    "        similarity_cos_cluster.append('BackVolley')\n",
    "    elif closest_cluster == 1 or closest_cluster == 13:\n",
    "        similarity_cos_cluster.append('Smash')\n",
    "    elif closest_cluster == 6 or closest_cluster == 11:\n",
    "        similarity_cos_cluster.append('Serve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e35b74cd-8570-4335-a7c6-b89db921a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_similarity(similarity, frame_index, classification_index):\n",
    "    if classification_index == 'Forehand':\n",
    "        return similarity[frame_index][0]\n",
    "        #return max(similarity[frame_index][4], similarity[frame_index][9], similarity[frame_index][3])\n",
    "    elif classification_index == 'Backhand':\n",
    "        return similarity[frame_index][1]\n",
    "        #return max(similarity[frame_index][2], similarity[frame_index][5], similarity[frame_index][7], similarity[frame_index][8])\n",
    "    elif classification_index == 'Backslice':\n",
    "        return similarity[frame_index][2]\n",
    "        #return max(similarity[frame_index][10], similarity[frame_index][12], similarity[frame_index][2], similarity[frame_index][7])\n",
    "    elif classification_index == 'ForeVolley':\n",
    "        return similarity[frame_index][3]\n",
    "        #return max(similarity[frame_index][3], similarity[frame_index][0])\n",
    "    elif classification_index == 'BackVolley':\n",
    "        return similarity[frame_index][4]\n",
    "        #return max(similarity[frame_index][7], similarity[frame_index][8])\n",
    "    elif classification_index == 'Smash':\n",
    "        return similarity[frame_index][5]\n",
    "        #return max(similarity[frame_index][1], similarity[frame_index][13])\n",
    "    elif classification_index == 'Serve':\n",
    "        return similarity[frame_index][6]\n",
    "        #return max(similarity[frame_index][6], similarity[frame_index][11], similarity[frame_index][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a40247b9-72f6-41ad-a811-7666b6a9c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame 분할 있음\n",
    "import cv2\n",
    "out_img_list = []\n",
    "out_index = 0\n",
    "frame_index = 0\n",
    "frame_cnt = 0\n",
    "is_detection = False\n",
    "threshold = 0.0035\n",
    "result_video = cv2.VideoCapture(video_path)\n",
    "width = int(result_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(result_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while result_video.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = result_video.read()\n",
    "\n",
    "    if success:\n",
    "        if out_index < len(anomaly_scores):\n",
    "            if anomaly_scores[out_index] < threshold:\n",
    "                if frame_cnt == 0:\n",
    "                    frame_index = out_index\n",
    "                    is_detection = True\n",
    "        if is_detection:\n",
    "            if frame_cnt < 60:\n",
    "                info = f'detection! -> {classification_list[frame_index][0]} : {cal_similarity(similarity_cos, frame_index, classification_list[frame_index][0]):.1%}, {similarity_cos_cluster[frame_index]}'\n",
    "                #info = f'detection! -> {classification_list[frame_index][0]} : {similarity[frame_index]:.1%}'\n",
    "                #info = f'detection! -> {classification_list[frame_index][0]} : {similarity_dtw_cluster[frame_index]}, {similarity_cos_cluster[frame_index]}, {similarity_procrustes_cluster[frame_index]} : {similarity_dtw[frame_index]:.1%}, {similarity_cos[frame_index]:.1%}, {similarity_procrustes[frame_index]:.1%}'\n",
    "                cv2.putText(frame, info, (45, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), thickness=3)\n",
    "                frame_cnt += 1\n",
    "            else:\n",
    "                frame_cnt = 0\n",
    "                is_detection = False\n",
    "        out_img_list.append(frame)\n",
    "        out_index += 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "result_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1ac15b8d-9112-4ff9-ba52-171980cb7633",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './result_video3_each_cos_weight.mp4'\n",
    "fourcc =  cv2.VideoWriter_fourcc(*'DIVX')\n",
    "fps = 30\n",
    "isColor = True\n",
    "out = cv2.VideoWriter(filename, fourcc, fps, (width, height), isColor)\n",
    "for out_img in out_img_list:\n",
    "    out.write(out_img)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4d26b7-c202-4af4-a888-251d4e8be831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame 분할 없음\n",
    "import cv2\n",
    "out_img_list = []\n",
    "out_index = 0\n",
    "threshold = 0.004\n",
    "result_video = cv2.VideoCapture('./video/test_video.mp4')\n",
    "width = int(result_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(result_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while result_video.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = result_video.read()\n",
    "\n",
    "    if success:\n",
    "        if out_index < len(anomaly_scores):\n",
    "            if anomaly_scores[out_index] < threshold:\n",
    "                info = f'detection! -> {classification_list[out_index][0]}, {similarity_cluster[out_index]} : {similarity[out_index]}%'\n",
    "                cv2.putText(frame, info, (45, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), thickness=3)\n",
    "        out_img_list.append(frame)\n",
    "        out_index = out_index + 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "result_video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4872cc7b-4837-4ffb-ace4-9a2c76f71ed1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
